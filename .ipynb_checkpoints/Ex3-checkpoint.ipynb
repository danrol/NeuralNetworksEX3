{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-010f228cec50>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\.conda\\envs\\vroscopy2\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_DATA\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_fscore(networks):\n",
    "    for i in range(len(networks)):\n",
    "        for j in range(len(networks) - 1):\n",
    "            if networks[j] < networks[j + 1]:\n",
    "                networks[j], networks[j + 1] = networks[j + 1], networks[j]\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.random.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape, dtype=None, name=\"Const\")\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv2d(x, w, padding='SAME'):\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding=padding)\n",
    "\n",
    "\n",
    "def max_pooling_2x2(x, padding='SAME'):\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "    # scores for data will be kept in the following order:\n",
    "    # fscore, accuracy, recall, precision = ['train', 'validation', 'test']\n",
    "    class DataType:\n",
    "        Names = [\"TRAIN\", \"VALIDATION\", \"TEST\"]\n",
    "        TRAIN = 0\n",
    "        VALIDATION = 1\n",
    "        TEST = 2\n",
    "\n",
    "    def __init__(self, session, network_type, batch_size=100, num_iterations=13000, keep_probability_value=0.5):\n",
    "        \"\"\"\n",
    "        :type session: tensorflow session object\n",
    "        :type network_type: network creator function pointer\n",
    "        \"\"\"\n",
    "        self.fscore = [0, 0, 0]\n",
    "        self.accuracy = [0, 0, 0]\n",
    "        self.recall = [0, 0, 0]\n",
    "        self.precision = [0, 0, 0]\n",
    "        self.keep_probability_value = keep_probability_value\n",
    "        self.x_placeholder = None\n",
    "        self.z_variables = None\n",
    "        self.keep_prob_placeholder = None\n",
    "        self.target_placeholder = None\n",
    "        self.session = session\n",
    "        self.batch_size = batch_size\n",
    "        self.num_iterations = num_iterations\n",
    "        self.net_type = network_type\n",
    "        self.net = None\n",
    "        self.train_time = timedelta(seconds=0)\n",
    "        self.num_weights_in_net = None\n",
    "        self.net_parameters = None\n",
    "        self.is_conv_net = False\n",
    "\n",
    "    def run(self):\n",
    "        self.build_train()\n",
    "        self.test_all_scores()\n",
    "\n",
    "    def build_train(self):\n",
    "        self.net = self.net_type()  # create network\n",
    "\n",
    "        self.x_placeholder = self.net[0]\n",
    "        self.z_variables = self.net[1]\n",
    "        self.keep_prob_placeholder = self.net[2]\n",
    "        self.target_placeholder = self.net[3]\n",
    "\n",
    "        self.net_parameters = self.net[4]\n",
    "\n",
    "        self.num_weights_in_net = self.net_parameters[4]\n",
    "        if self.keep_prob_placeholder is not None:\n",
    "            self.is_conv_net = True\n",
    "\n",
    "        self.train_network()\n",
    "        logging.info(str(self))\n",
    "\n",
    "    def score(self, y_values, t_values, data_type_enum, printlog=False):\n",
    "        y_val, t_val = np.argmax(y_values, 1), np.argmax(t_values, 1)\n",
    "\n",
    "        self.accuracy[data_type_enum] = accuracy_score(t_val, y_val)\n",
    "\n",
    "        self.fscore[data_type_enum] = f1_score(t_val, y_val, average=\"macro\")\n",
    "\n",
    "        # self.precision[data_type_enum] = precision_score(t_val, y_val, average=\"macro\")\n",
    "        self.precision[data_type_enum] = precision_score(t_val, y_val, average=\"macro\", zero_division=0)\n",
    "\n",
    "        # self.recall[data_type_enum] = recall_score(t_val, y_val, average=\"macro\")\n",
    "        self.recall[data_type_enum] = recall_score(t_val, y_val, average=\"macro\", zero_division=0)\n",
    "        if printlog:\n",
    "            logging.info(self.scores_str(data_type_enum))\n",
    "\n",
    "    def test_all_scores(self):\n",
    "        logging.debug(\"test_all_scores begin\")\n",
    "\n",
    "        y_values, t_values = self.predict(data=mnist.train, use_batch=True)\n",
    "        self.score(y_values, t_values, Network.DataType.TRAIN)\n",
    "\n",
    "        y_values, t_values = self.predict(data=mnist.validation, use_batch=True)\n",
    "        self.score(y_values, t_values, Network.DataType.VALIDATION)\n",
    "\n",
    "        y_values, t_values = self.predict(data=mnist.test, use_batch=True)\n",
    "        self.score(y_values, t_values, Network.DataType.TEST)\n",
    "        logging.debug(\"test_all_scores end\")\n",
    "\n",
    "    def predict(self, data, use_batch=False):\n",
    "        if use_batch:\n",
    "            batch_x, batch_t = data.next_batch(self.batch_size)\n",
    "        else:\n",
    "            batch_x, batch_t = data.images, data.labels  # use whole database\n",
    "\n",
    "        if self.keep_prob_placeholder is None:  # check if conv net or not\n",
    "            y = self.session.run(self.net[1], feed_dict={self.x_placeholder: batch_x})\n",
    "        else:\n",
    "            y = self.session.run(self.net[1], feed_dict={self.x_placeholder: batch_x, self.keep_prob_placeholder: 1})\n",
    "        return y, batch_t\n",
    "\n",
    "    def scores_str(self, data_type_enum=None):\n",
    "        s = \"\"\n",
    "        if data_type_enum is not None:\n",
    "            if data_type_enum == Network.DataType.TRAIN:\n",
    "                s = s + \"\\n\"\n",
    "            s = s + \" - \" + Network.DataType.Names[data_type_enum] + \": \"\n",
    "            s = s + \"Network Scores\\n\\tAccuracy: \" + str(self.accuracy[data_type_enum]) + \" Fscore: \" + str(self.fscore[data_type_enum]) + \"\\n\\tPrecision: \" + str(self.precision[\n",
    "                                                                                                                                                                       data_type_enum]) \\\n",
    "                + \" recall: \" + str(self.recall[data_type_enum]) + \"\\n\"\n",
    "        else:\n",
    "            s = self.scores_str(Network.DataType.TRAIN)\n",
    "            s = s + (self.scores_str(Network.DataType.VALIDATION))\n",
    "            s = s + (self.scores_str(Network.DataType.TEST))\n",
    "        return s\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"Batch_size=\" + str(self.batch_size) + \" Num training iterations=\" + str(self.num_iterations) + \" dropout_rate=\" + str(self.keep_probability_value)\n",
    "        s = s + \"\\n\\t\\tTraining time is : \" + str(self.train_time)\n",
    "        s = s + \"\\n\\t\\tNumber of weights in net is : \" + str(self.num_weights_in_net)\n",
    "        return s\n",
    "\n",
    "    def find_data_value(self, image):\n",
    "        z = self.session.run([self.z_variables], {self.x_placeholder: [image], self.keep_prob_placeholder: 1})\n",
    "        return np.argmax(z[0], 1)[0]\n",
    "\n",
    "    def visualize(self, image, layer_num, channel_num, before_activation=False):\n",
    "        if layer_num != 0 and self.is_conv_net:\n",
    "            conv_layer = self.net[layer_num + 4]\n",
    "            if before_activation:\n",
    "                the_layer = conv_layer[0]\n",
    "            else:\n",
    "                the_layer = conv_layer[1]\n",
    "            z, layer = self.session.run([self.z_variables, the_layer], {self.x_placeholder: [image], self.keep_prob_placeholder: 1})\n",
    "            prediction = np.argmax(z, 1)\n",
    "            logging.info(\"Printing layer number \" + str(layer_num) + \" channel number: \" + str(channel_num) + \" for predicted value \" + str(prediction) + ( \"before relu \" if before_activation else \" after relu\"))\n",
    "            num_filters = conv_layer[4]\n",
    "            x_size = conv_layer[2]\n",
    "            y_size = conv_layer[3]\n",
    "            first_image = np.transpose(np.array(layer[0], dtype='float').reshape((x_size * y_size, num_filters)))  # 28x28, filter size\n",
    "            # change this according to picture size and filter size in layer\n",
    "            pixels = first_image[channel_num].reshape((x_size, y_size))\n",
    "\n",
    "        else:  # print the input\n",
    "            logging.info(\"Invalid input, printing the image as is\")\n",
    "            first_image = np.array(image, dtype='float')  # 28x28, filter size\n",
    "            x_size = self.net_parameters[0]\n",
    "            y_size = self.net_parameters[1]\n",
    "            pixels = first_image.reshape((x_size, y_size))\n",
    "\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    def train_network(self):\n",
    "        iteration_number_for_target_accuracy = None\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.target_placeholder, logits=self.z_variables))\n",
    "        train_step = tf.compat.v1.train.AdamOptimizer(name=\"Adam\").minimize(cross_entropy)\n",
    "        tf.compat.v1.global_variables_initializer().run()\n",
    "        t1 = timer()\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            batch_xsx, batch_ts = mnist.train.next_batch(batch_size=self.batch_size)\n",
    "            if self.keep_prob_placeholder is None:\n",
    "                ts, ce = self.session.run([train_step, cross_entropy], feed_dict={self.x_placeholder: batch_xsx, self.target_placeholder: batch_ts})\n",
    "            else:\n",
    "                ts, ce = self.session.run([train_step, cross_entropy],\n",
    "                                          feed_dict={self.x_placeholder: batch_xsx, self.target_placeholder: batch_ts, self.keep_prob_placeholder: self.keep_probability_value})\n",
    "\n",
    "            if iteration_number_for_target_accuracy is None:\n",
    "                y_values, t_values = self.predict(data=mnist.validation, use_batch=True)\n",
    "                self.score(y_values, t_values, Network.DataType.VALIDATION)\n",
    "                if self.accuracy[Network.DataType.VALIDATION] >= 0.99:\n",
    "                    iteration_number_for_target_accuracy = _\n",
    "                    t3 = timer()\n",
    "                    break\n",
    "        if iteration_number_for_target_accuracy is not None:\n",
    "            logging.info(\"Reached 99% accuracy within \" + str(iteration_number_for_target_accuracy) + \" iterations and \" + str(timedelta(seconds=t3 - t1)))\n",
    "        t2 = timer()\n",
    "        self.train_time = timedelta(seconds=t2 - t1)\n",
    "        logging.info(\"Training time is : \" + str(self.train_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression_with_layer(x_input_size=28, y_input_size=28, n_output=10, n_hidden1=200, n_hidden2=200):\n",
    "    logging.info(\"***********LOGISTIC REGRESSION WITH LAYER***********\")\n",
    "    logging.info(\"Layer 1 size = \" + str(n_hidden1) + \" Layer 2 size = \" + str(n_hidden2))\n",
    "    n_input = x_input_size * y_input_size\n",
    "    seed = tf.compat.v1.set_random_seed(random.randint(1, 1000))\n",
    "    x = tf.compat.v1.placeholder(tf.float32, [None, n_input], name=\"Inputs\")\n",
    "    t = tf.compat.v1.placeholder(tf.float32, [None, n_output], name=\"Targets\")\n",
    "    h1 = tf.Variable(tf.random.uniform([n_input, n_hidden1], -1, 1, seed=seed), name=\"h1\")\n",
    "    b1 = tf.Variable(tf.random.uniform([1, n_hidden1], -1, 1, seed=seed), name=\"b1\")\n",
    "    h2 = tf.Variable(tf.random.uniform([n_hidden1, n_hidden2], -1, 1, seed=seed), name=\"h2\")\n",
    "    b2 = tf.Variable(tf.random.uniform([1, n_hidden2], -1, 1, seed=seed), name=\"b2\")\n",
    "    w = tf.Variable(tf.random.uniform([n_hidden2, n_output], -1, 1, seed=seed), name=\"Out_layer_w\")\n",
    "    b = tf.Variable(tf.random.uniform([1, n_output], -1, 1, seed=seed), name=\"Out_biases\")\n",
    "\n",
    "    h1_s = tf.add(tf.matmul(x, h1), b1)\n",
    "    h1_s_rel = tf.nn.relu(h1_s)\n",
    "    h2_s = tf.add(tf.matmul(h1_s_rel, h2), b2)\n",
    "    h2_s_rel = tf.nn.relu(h2_s)\n",
    "    z = tf.add(tf.matmul(h2_s_rel, w), b)\n",
    "    num_weights_in_net = n_input * n_hidden1 + n_hidden1 + n_hidden1 * n_hidden2 + n_hidden2 + n_hidden2 * n_output + n_output\n",
    "    net_parameters = [x_input_size, y_input_size, n_output, [n_hidden1, n_hidden2], num_weights_in_net]\n",
    "    return [x, z, None, t, h1_s, net_parameters, h1_s, h1_s_rel, h2_s, h2_s_rel]\n",
    "\n",
    "\n",
    "def logistic_regression(x_input_size=28, y_input_size=28, n_output=10):\n",
    "    n_input = x_input_size * y_input_size\n",
    "    num_weights_in_net = n_input * n_output + n_output\n",
    "    logging.info(\"***********LOGISTIC REGRESSION***********\")\n",
    "    logging.info(\"input size = \" + str(n_input) + \" output size = \" + str(n_output))\n",
    "    seed = tf.compat.v1.set_random_seed(random.randint(1, 1000))\n",
    "    x = tf.compat.v1.placeholder(tf.float32, [None, n_input], name=\"Inputs\")\n",
    "    t = tf.compat.v1.placeholder(tf.float32, [None, n_output], name=\"Targets\")\n",
    "    w = tf.Variable(tf.random.uniform([n_input, n_output], -1, 1, seed=seed), name=\"Out_layer_w\")\n",
    "    b = tf.Variable(tf.random.uniform([n_output], -1, 1, seed=seed), name=\"Out_biases\")\n",
    "    z = tf.add(tf.matmul(x, w), b)\n",
    "\n",
    "    net_parameters = [x_input_size, y_input_size, n_output, [], num_weights_in_net]\n",
    "    return [x, z, None, t, net_parameters]\n",
    "\n",
    "\n",
    "def logistic_regression_conv_layers(x_input_size=28, y_input_size=28, n_output=10, num_filters1=32, num_filters2=64, drop_rate_percent=0.5, x_filter_size=5,\n",
    "                                    y_filter_size=5, dimension_size=1, hidden_layer_size=1024):\n",
    "    logging.info(\"***********LOGISTIC REGRESSION WITH CONVOLUTION***********\")\n",
    "    num_weights_in_net = dimension_size * x_filter_size * y_filter_size * (num_filters1 + 1)\n",
    "    num_weights_in_net += x_filter_size * y_filter_size * num_filters1 * (num_filters2 + 1)\n",
    "\n",
    "    x = tf.compat.v1.placeholder(tf.float32, [None, x_input_size * y_input_size])\n",
    "    t = tf.compat.v1.placeholder(tf.float32, [None, n_output], name=\"Targets\")\n",
    "    w_conv1 = weight_variable([x_filter_size, y_filter_size, dimension_size, num_filters1])  # 32 filters of 5x5x1 (x axis, y axis, dimension (greyscale is 1))\n",
    "    b_conv1 = bias_variable([num_filters1])\n",
    "\n",
    "    w_conv2 = weight_variable([x_filter_size, y_filter_size, num_filters1, num_filters2])\n",
    "    b_conv2 = bias_variable([num_filters2])\n",
    "\n",
    "    x_image = tf.reshape(x, [-1, x_input_size, y_input_size, 1])\n",
    "    h_conv1 = conv2d(x_image, w_conv1) + b_conv1\n",
    "    h_conv1_relu = tf.nn.relu(h_conv1)\n",
    "    h_pool1 = max_pooling_2x2(h_conv1_relu)\n",
    "    h_conv2 = conv2d(h_pool1, w_conv2) + b_conv2\n",
    "    h_conv2_relu = tf.nn.relu(h_conv2)\n",
    "    h_pool2 = max_pooling_2x2(h_conv2_relu)\n",
    "\n",
    "    # Fully connected layer 1024\n",
    "    x_size_after_pool1 = int(x_input_size / 2)\n",
    "    y_size_after_pool1 = int(y_input_size / 2)\n",
    "\n",
    "    x_size_after_pool2 = int(x_input_size / 4)\n",
    "    y_size_after_pool2 = int(y_input_size / 4)\n",
    "\n",
    "    w_fc1 = weight_variable([x_size_after_pool2 * y_size_after_pool2 * num_filters2, hidden_layer_size])\n",
    "    b_fc1 = bias_variable([hidden_layer_size])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, x_size_after_pool2 * y_size_after_pool2 * num_filters2])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "    keep_prob = tf.compat.v1.placeholder(tf.float32)\n",
    "    rate = 1 - keep_prob\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, rate=rate)\n",
    "\n",
    "    w_fc2 = weight_variable([hidden_layer_size, n_output])\n",
    "    b_fc2 = bias_variable([n_output])\n",
    "    y_conv = tf.matmul(h_fc1_drop, w_fc2) + b_fc2\n",
    "\n",
    "    tf.compat.v1.global_variables_initializer().run()\n",
    "    #   [x_size, y_size, output_size, ['hidden layer size'...], num_weights_in_net]\n",
    "    net_parameters = [x_input_size, y_input_size, n_output, [hidden_layer_size], num_weights_in_net]\n",
    "    return [x, y_conv, keep_prob, t, net_parameters, [h_conv1, h_conv1_relu, x_input_size, y_input_size, num_filters1],\n",
    "            [h_conv2, h_conv2_relu, x_size_after_pool1, y_size_after_pool1, num_filters2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_networks(session):\n",
    "    networks = []\n",
    "    # the following for loops set the network type and other parameters\n",
    "    for batch_size in [50, 100]:\n",
    "        for train_range in [13000]:\n",
    "        net = Network(session=session, network_type=logistic_regression, batch_size=batch_size, num_iterations=train_range)\n",
    "        networks.append(net)\n",
    "\n",
    "        net = Network(session=session, network_type=logistic_regression_with_layer, batch_size=batch_size, num_iterations=train_range)\n",
    "        networks.append(net)\n",
    "        for dropout in [0.5]:\n",
    "            net = Network(session=session, network_type=logistic_regression_conv_layers, batch_size=batch_size, num_iterations=train_range, keep_probability_value=dropout)\n",
    "            networks.append(net)\n",
    "    return networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***********LOGISTIC REGRESSION WITH CONVOLUTION***********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reached 99% accuracy within 50 iterations and 0:00:02.786721\n",
      "INFO:root:Training time is : 0:00:02.789332\n",
      "INFO:root:Batch_size=10 Num training iterations=100 dropout_rate=0.5\n",
      "\t\tTraining time is : 0:00:02.789332\n",
      "\t\tNumber of weights in net is : 52825\n",
      "INFO:root:\n",
      " - TRAIN: Network Scores\n",
      "\tAccuracy: 0.9 Fscore: 0.9333333333333333\n",
      "\tPrecision: 0.9375 recall: 0.9583333333333333\n",
      " - VALIDATION: Network Scores\n",
      "\tAccuracy: 0.8 Fscore: 0.8285714285714285\n",
      "\tPrecision: 0.8571428571428571 recall: 0.880952380952381\n",
      " - TEST: Network Scores\n",
      "\tAccuracy: 1.0 Fscore: 1.0\n",
      "\tPrecision: 1.0 recall: 1.0\n",
      "\n",
      "INFO:root:Printing net with fscore value = [0.9333333333333333, 0.8285714285714285, 1.0]\n",
      "INFO:root:Printing layer number 1 channel number: 10 for predicted value [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Printing layer number 1 channel number: 10 for predicted value [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Printing layer number 2 channel number: 10 for predicted value [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Printing layer number 2 channel number: 10 for predicted value [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #  this command forces to use CPU instead of GPU\n",
    "# logging.basicConfig(level=logging.INFO, filename='logger.log', filemode='w')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "networks = create_networks(session=sess)\n",
    "# begin training networks - run performs buildTrain, predict, score and visualize\n",
    "for network in networks:\n",
    "    network.run()\n",
    "    logging.info(network.scores_str())\n",
    "sort_by_fscore(networks)\n",
    "\n",
    "for i in range(50):\n",
    "    image = mnist.test.images[i]\n",
    "    val = networks[0].find_data_value(image)\n",
    "    if val == 6:\n",
    "        break\n",
    "\n",
    "for net_index in range(5):  # print image for 5 networks with best fscores\n",
    "    if net_index <= (len(networks) - 1):\n",
    "        logging.info(\"Printing net with fscore value = \" + str(networks[net_index].fscore))\n",
    "        networks[net_index].visualize(image=image, layer_num=1, channel_num=10, before_activation=False)\n",
    "        networks[net_index].visualize(image=image, layer_num=1, channel_num=10, before_activation=True)\n",
    "        networks[net_index].visualize(image=image, layer_num=2, channel_num=10, before_activation=False)\n",
    "        networks[net_index].visualize(image=image, layer_num=2, channel_num=10, before_activation=True)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
